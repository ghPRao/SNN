{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, Activation,AveragePooling2D\n",
    "from keras import backend as K\n",
    " \n",
    "num_classes = 10\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclid_dis(vects):\n",
    "  x,y = vects\n",
    "  sum_square = K.sum(K.square(x-y), axis=1, keepdims=True)\n",
    "  return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    " \n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    " \n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    y_true=tf.dtypes.cast(y_true, tf.float64)\n",
    "    y_pred=tf.dtypes.cast(y_pred, tf.float64)\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "def create_pairs(x, digit_indices):\n",
    "  pairs = []\n",
    "  labels = []\n",
    "   \n",
    "  n=min([len(digit_indices[d]) for d in range(num_classes)]) -1\n",
    "   \n",
    "  for d in range(num_classes):\n",
    "    for i in range(n):\n",
    "      z1, z2 = digit_indices[d][i], digit_indices[d][i+1]\n",
    "      pairs += [[x[z1], x[z2]]]\n",
    "      inc = random.randrange(1, num_classes)\n",
    "      dn = (d + inc) % num_classes\n",
    "      z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "      pairs += [[x[z1], x[z2]]]\n",
    "      labels += [1,0]\n",
    "  return np.array(pairs), np.array(labels)\n",
    " \n",
    " \n",
    "def create_base_net(input_shape):\n",
    "   \n",
    "  input = Input(shape = input_shape)\n",
    "  x = Conv2D(4, (5,5), activation = 'tanh')(input)\n",
    "  x = AveragePooling2D(pool_size = (2,2))(x)\n",
    "  x = Conv2D(16, (5,5), activation = 'tanh')(x)\n",
    "  x = AveragePooling2D(pool_size = (2,2))(x)\n",
    "  x = Flatten()(x)\n",
    "  x = Dense(10, activation = 'tanh')(x)\n",
    "  model = Model(input, x)\n",
    "  model.summary()\n",
    "  return model\n",
    " \n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)\n",
    " \n",
    " \n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    " \n",
    " \n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (1, 28, 28)\n",
    "print(x_train.shape)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    " \n",
    "input_shape = x_train.shape[1:]\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 24, 24, 4)         104       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 12, 12, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 16)          1616      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 4,290\n",
      "Trainable params: 4,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create training+test positive and negative pairs\n",
    "digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
    "tr_pairs, tr_y = create_pairs(x_train, digit_indices)\n",
    " \n",
    "digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\n",
    "te_pairs, te_y = create_pairs(x_test, digit_indices)\n",
    " \n",
    "# network definition\n",
    "base_network = create_base_net(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "847/847 [==============================] - 27s 31ms/step - loss: 0.1325 - accuracy: 0.8352 - val_loss: 0.0784 - val_accuracy: 0.9290\n",
      "Epoch 2/20\n",
      "847/847 [==============================] - 27s 32ms/step - loss: 0.0826 - accuracy: 0.9229 - val_loss: 0.0629 - val_accuracy: 0.9505\n",
      "Epoch 3/20\n",
      "847/847 [==============================] - 28s 33ms/step - loss: 0.0687 - accuracy: 0.9451 - val_loss: 0.0617 - val_accuracy: 0.9436\n",
      "Epoch 4/20\n",
      "847/847 [==============================] - 28s 33ms/step - loss: 0.0625 - accuracy: 0.9528 - val_loss: 0.0528 - val_accuracy: 0.9640\n",
      "Epoch 5/20\n",
      "847/847 [==============================] - 27s 32ms/step - loss: 0.0578 - accuracy: 0.9579 - val_loss: 0.0500 - val_accuracy: 0.9629\n",
      "Epoch 6/20\n",
      "847/847 [==============================] - 30s 35ms/step - loss: 0.0546 - accuracy: 0.9602 - val_loss: 0.0484 - val_accuracy: 0.9679\n",
      "Epoch 7/20\n",
      "847/847 [==============================] - 29s 34ms/step - loss: 0.0517 - accuracy: 0.9639 - val_loss: 0.0457 - val_accuracy: 0.9698\n",
      "Epoch 8/20\n",
      "847/847 [==============================] - 27s 32ms/step - loss: 0.0490 - accuracy: 0.9668 - val_loss: 0.0440 - val_accuracy: 0.9685\n",
      "Epoch 9/20\n",
      "847/847 [==============================] - 27s 32ms/step - loss: 0.0470 - accuracy: 0.9685 - val_loss: 0.0428 - val_accuracy: 0.9710\n",
      "Epoch 10/20\n",
      "847/847 [==============================] - 26s 31ms/step - loss: 0.0457 - accuracy: 0.9698 - val_loss: 0.0427 - val_accuracy: 0.9763\n",
      "Epoch 11/20\n",
      "847/847 [==============================] - 26s 31ms/step - loss: 0.0447 - accuracy: 0.9713 - val_loss: 0.0423 - val_accuracy: 0.9696\n",
      "Epoch 12/20\n",
      "847/847 [==============================] - 26s 31ms/step - loss: 0.0438 - accuracy: 0.9711 - val_loss: 0.0405 - val_accuracy: 0.9742\n",
      "Epoch 13/20\n",
      "847/847 [==============================] - 27s 32ms/step - loss: 0.0423 - accuracy: 0.9733 - val_loss: 0.0399 - val_accuracy: 0.9771\n",
      "Epoch 14/20\n",
      "847/847 [==============================] - 27s 31ms/step - loss: 0.0416 - accuracy: 0.9731 - val_loss: 0.0385 - val_accuracy: 0.9758\n",
      "Epoch 15/20\n",
      "847/847 [==============================] - 26s 30ms/step - loss: 0.0414 - accuracy: 0.9735 - val_loss: 0.0381 - val_accuracy: 0.9781\n",
      "Epoch 16/20\n",
      "847/847 [==============================] - 27s 32ms/step - loss: 0.0406 - accuracy: 0.9750 - val_loss: 0.0384 - val_accuracy: 0.9724\n",
      "Epoch 17/20\n",
      "847/847 [==============================] - 29s 34ms/step - loss: 0.0400 - accuracy: 0.9751 - val_loss: 0.0367 - val_accuracy: 0.9752\n",
      "Epoch 18/20\n",
      "847/847 [==============================] - 27s 32ms/step - loss: 0.0397 - accuracy: 0.9748 - val_loss: 0.0375 - val_accuracy: 0.9731\n",
      "Epoch 19/20\n",
      "847/847 [==============================] - 28s 34ms/step - loss: 0.0386 - accuracy: 0.9766 - val_loss: 0.0371 - val_accuracy: 0.9749\n",
      "Epoch 20/20\n",
      "847/847 [==============================] - 30s 35ms/step - loss: 0.0381 - accuracy: 0.9770 - val_loss: 0.0361 - val_accuracy: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9f241029d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    " \n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    " \n",
    "distance = Lambda(euclid_dis,\n",
    "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    " \n",
    "model = Model([input_a, input_b], distance)\n",
    "#train\n",
    "model.compile(loss=contrastive_loss, optimizer='adam', metrics=[accuracy])\n",
    "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          batch_size=128,\n",
    "          epochs=epochs,\n",
    "          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Accuracy on training set: 97.80%\n",
      "* Accuracy on test set: 97.81%\n"
     ]
    }
   ],
   "source": [
    "# compute final accuracy on training and test sets\n",
    "y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(tr_y, y_pred)\n",
    "y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(te_y, y_pred)\n",
    " \n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "number_of_items = 15\n",
    " \n",
    " \n",
    "im = tf.keras.preprocessing.image.array_to_img(\n",
    "    tr_pairs[1,0],\n",
    "    data_format=None,\n",
    "    scale=True,\n",
    "    dtype=None\n",
    ")\n",
    " \n",
    "plt.figure(figsize=(20, 10))\n",
    "for item in range(number_of_items):\n",
    "    display = plt.subplot(1, number_of_items,item+1)\n",
    "    im = tf.keras.preprocessing.image.array_to_img( tr_pairs[item,0], data_format=None, scale=True,dtype=None)\n",
    "    plt.imshow(im, cmap=\"gray\")\n",
    "    display.get_xaxis().set_visible(False)\n",
    "    display.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    " \n",
    "plt.figure(figsize=(20, 10))\n",
    "for item in range(number_of_items):\n",
    "    display = plt.subplot(1, number_of_items,item+1)\n",
    "    im = tf.keras.preprocessing.image.array_to_img( tr_pairs[item,1], data_format=None, scale=True,dtype=None)\n",
    "    plt.imshow(im, cmap=\"gray\")\n",
    "    display.get_xaxis().set_visible(False)\n",
    "    display.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    " \n",
    "for i in range(number_of_items):\n",
    "  print(y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.mygreatlearning.com/blog/siamese-networks/#sh3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
